#!/usr/bin/env python
import sys
sys.path.append('../.')
sys.path.append('.')

import os
import os.path as path
import getpass
import glob
import optparse
import socket
import shutil
import time
import numpy as np
import h5py
from empryonic import track
from empryonic import io

def generate_traxelstore(h5file,
			 feature_path,
			 time_range,
			 x_range,
			 y_range,
			 z_range,
			 size_range,
			 x_scale=1.0,
			 y_scale=1.0,
			 z_scale=1.0,
			 with_div=False,
			 with_local_centers=False,
			 median_object_size=None,
			 max_traxel_id_at=None):

    
    print "generating traxels"
    print "fetching region features and division probabilities"
    print h5file, feature_path

    feats = h5file[feature_path]
    feats = h5file[feature_path]['samples']
    
    if with_div and 'ClassProbabilities' in h5file[feature_path].keys():
        #divProbs = None # self.ClassMapping(time_range).wait()
        divProbs = h5file[feature_path]['ClassProbabilities']
	
    if with_local_centers:
        localCenters = None # self.RegionLocalCenters(time_range).wait()
        
    print "filling traxelstore"
    ts = track.TraxelStore()

    if x_range is None:
        x_range = [0, sys.maxint]

    if y_range is None:
        y_range = [0, sys.maxint]

    if z_range is None:
        z_range = [0, sys.maxint]

    keys_sorted = sorted(feats.keys(), key=int)
    if time_range is not None:
        keys_sorted = [key for key in keys_sorted if int(key) >= time_range[0] and int(key) < time_range[1]]
    
    
    max_traxel_id_at = track.VectorOfInt()  
    filtered_labels = {}        
    obj_sizes = []
    total_count = 0
    empty_frame = False
    for t in keys_sorted:
        rc = feats[t]['0']['RegionCenter']
        if rc.size:
           rc = rc[1:, ...]

        ct = feats[t]['0']['Count']
        if ct.size:
           ct = ct[1:, ...]
            
        print "at timestep ", t, rc.shape[0], "traxels found"
        count = 0
        filtered_labels[t] = []
        for idx in range(rc.shape[0]):
            x, y, z = rc[idx]
            size = ct[idx]
            if (x < x_range[0] or x >= x_range[1] or
                y < y_range[0] or y >= y_range[1] or
                z < z_range[0] or z >= z_range[1] or
                size < size_range[0] or size >= size_range[1]):
                filtered_labels[t].append(int(idx + 1))
                continue
            else:
                count += 1
            tr = track.Traxel()
            tr.set_x_scale(x_scale)
            tr.set_y_scale(y_scale)
            tr.set_z_scale(z_scale)
            tr.Id = int(idx + 1)
            tr.Timestep = int(t)
            
            tr.add_feature_array("com", len(rc[idx]))                
            for i, v in enumerate(rc[idx]):
                tr.set_feature_value('com', i, float(v))
            
            if with_div:
                tr.add_feature_array("divProb", 1)
                # idx+1 because rc and ct start from 1, divProbs starts from 0
                tr.set_feature_value("divProb", 0, float(divProbs[str(t)][idx+1][1]))
            
            if with_local_centers:
                tr.add_feature_array("localCentersX", len(localCenters[t][idx+1]))  
                tr.add_feature_array("localCentersY", len(localCenters[t][idx+1]))
                tr.add_feature_array("localCentersZ", len(localCenters[t][idx+1]))            
                for i, v in enumerate(localCenters[t][idx+1]):
                    tr.set_feature_value("localCentersX", i, float(v[0]))
                    tr.set_feature_value("localCentersY", i, float(v[1]))
                    tr.set_feature_value("localCentersZ", i, float(v[2]))                
            
            tr.add_feature_array("count", 1)
            tr.set_feature_value("count", 0, float(size))
            if median_object_size is not None:
                obj_sizes.append(float(size))
            ts.add(tr)   
                     
        print "at timestep ", t, count, "traxels passed filter"
        max_traxel_id_at.append(int(rc.shape[0]))
        if count == 0:
            empty_frame = True
            
        total_count += count
    
    if median_object_size is not None:
        median_object_size[0] = np.median(np.array(obj_sizes),overwrite_input=True)
        print 'median object size = ' + str(median_object_size[0])
    
    return ts # , filtered_labels, empty_frame


def write_detections(detections, fn):
	with io.LineageH5(fn, 'r') as f:
		traxel_ids = f['objects/meta/id'].value
		valid = f['objects/meta/valid'].value
	assert(len(traxel_ids) == len(valid))
	assert(len(detections) == len(np.flatnonzero(valid)))

	detection_indicator = np.zeros(len(traxel_ids), dtype=np.uint16)

	for i, traxel_id in enumerate(traxel_ids):
		if valid[i] != 0:
			if detections[int(traxel_id)]:
				detection_indicator[i] = 1
			else:
				detection_indicator[i] = 0
	
	with io.LineageH5(fn, 'r+') as f:
            # delete old dataset
            if "detection" in f['objects/meta'].keys():
                del f["objects/meta/detection"]
	    f.create_dataset('objects/meta/detection', data=detection_indicator)
            

def write_events(events, fn):
        dis = []
        app = []
        div = []
        mov = []
        mer = []
        print "-- Writing results to " + path.basename(fn)
        for event in events:
            if event.type == track.EventType.Appearance:
                app.append((event.traxel_ids[0], event.energy))
            if event.type == track.EventType.Disappearance:
                dis.append((event.traxel_ids[0], event.energy))
            if event.type == track.EventType.Division:
                div.append((event.traxel_ids[0], event.traxel_ids[1], event.traxel_ids[2], event.energy))
            if event.type == track.EventType.Move:
                mov.append((event.traxel_ids[0], event.traxel_ids[1], event.energy))
            if event.type == track.EventType.Merger:
                mer.append((event.traxel_ids[0], event.traxel_ids[1], event.energy))

        # convert to ndarray for better indexing
        dis = np.asarray(dis)
        app = np.asarray(app)
        div = np.asarray(div)
        mov = np.asarray(mov)
        mer = np.asarray(mer)

        # write only if file exists
        with io.LineageH5(fn, 'w') as f_curr:
            # delete old tracking
            if "tracking" in f_curr.keys():
                del f_curr["tracking"]

            tg = f_curr.create_group("tracking")
            
            # write associations
            if len(app):
                ds = tg.create_dataset("Appearances", data=app[:, :-1], dtype=np.int32)
                ds.attrs["Format"] = "cell label appeared in current file"

                ds = tg.create_dataset("Appearances-Energy", data=app[:, -1], dtype=np.double)
                ds.attrs["Format"] = "lower energy -> higher confidence"

            if len(dis):
                ds = tg.create_dataset("Disappearances", data=dis[:, :-1], dtype=np.int32)
                ds.attrs["Format"] = "cell label disappeared in current file"

                ds = tg.create_dataset("Disappearances-Energy", data=dis[:, -1], dtype=np.double)
                ds.attrs["Format"] = "lower energy -> higher confidence"


            if len(mov):
                ds = tg.create_dataset("Moves", data=mov[:, :-1], dtype=np.int32)
                ds.attrs["Format"] = "from (previous file), to (current file)"

                ds = tg.create_dataset("Moves-Energy", data=mov[:, -1], dtype=np.double)
                ds.attrs["Format"] = "lower energy -> higher confidence"

                
            if len(div):
                ds = tg.create_dataset("Splits", data=div[:, :-1], dtype=np.int32)
                ds.attrs["Format"] = "ancestor (previous file), descendant (current file), descendant (current file)"

                ds = tg.create_dataset("Splits-Energy", data=div[:, -1], dtype=np.double)
                ds.attrs["Format"] = "lower energy -> higher confidence"

	    if len(mer):
                ds = tg.create_dataset("Mergers", data=mer[:, :-1], dtype=np.int32)
                ds.attrs["Format"] = "descendant (current file), number of objects"
		
                ds = tg.create_dataset("Mergers-Energy", data=mer[:, -1], dtype=np.double)
                ds.attrs["Format"] = "lower energy -> higher confidence"

        print "-> results successfully written"


        
if __name__ == "__main__":
    usage = """%prog [options] FILES
Track cells.

Before processing, input files are copied to OUT_DIR. Groups, that will not be modified are not
copied but linked to the original files to improve execution speed and storage requirements.
"""

    parser = optparse.OptionParser(usage=usage)
    parser.add_option('--method', type='str', default='conservation', help='chaingraph or conservation [default: %default]')
    parser.add_option('-o', '--output-dir', type='str', dest='out_dir', default='tracked', help='[default: %default]')
    parser.add_option('--x-scale', type='float', dest='x_scale', default=1., help='[default: %default]')
    parser.add_option('--y-scale', type='float', dest='y_scale', default=1., help='[default: %default]')
    parser.add_option('--z-scale', type='float', dest='z_scale', default=1., help='[default: %default]')
    parser.add_option('--with-visbricks', action='store_true', dest='with_visbricks', help='write out a "time dependent HDF5" file for visbricks')
    parser.add_option('--with-rel-linking', action='store_true', dest='with_rel_linking', help='link hdf5 files relative instead of absolute')
    parser.add_option('--full-copy', action='store_true', dest='full_copy', help='do not link to but copy input files completely')
    parser.add_option('--user', type='str', dest='user', default=getpass.getuser(), help='user to log [default: %default]')
    parser.add_option('--date', type='str', dest='date', default=time.ctime(), help='datetime to log [default: %default]')
    parser.add_option('--machine', type='str', dest='machine', default=socket.gethostname(), help='machine to log [default: %default]')
    parser.add_option('--comment', type='str', dest='comment', default='none', help='some comment to log [default: %default]')
    parser.add_option('--random-forest', type='string', dest='rf_fn', default=None, help='use cellness prediction instead of indicator function for (mis-)detection energy')
    parser.add_option('--ep_gap', type='float', dest='ep_gap', default=0.01, help='stop optimization as soon as a feasible integer solution is found proved to be within the given percent of the optimal solution')
    parser.add_option('-f', '--forbidden_cost', type='float', dest='forb', default=0, help='forbidden cost [default: %default]')
    parser.add_option('--min-ts', type='int', dest='mints', default=0, help='[default: %default]')
    parser.add_option('--max-ts', type='int', dest='maxts', default=-1, help='[default: %default]')
    

    chaingraphopts = optparse.OptionGroup(parser, "chaingraph method")
    chaingraphopts.add_option('-p', '--opportunity_cost', type='float', dest='opp', default=0, help='opportunity cost [default: %default]')
    
    chaingraphopts.add_option('--without-hard-constraints', action='store_true', dest='without_constraints', help='without hard constraints')
    chaingraphopts.add_option('--fixed-detections', action='store_true', dest='fixed_detections', help='set all detections to active via hard constraint; not affected by --without-hard-constraints')    
    chaingraphopts.add_option('--mean_div_dist', type='float', dest='mdd', default=25, help='average division distance [default: %default]')
    chaingraphopts.add_option('--min_angle', type='float', dest='ma', default=0, help='minimal division angle [default: %default]')
    chaingraphopts.add_option('-a', '--appearance', type='float', dest='app', default=500, help='appearance cost [default: %default]')
    chaingraphopts.add_option('-d', '--disappearance', type='float', dest='dis', default=500, help='disappearance cost [default: %default]')
    chaingraphopts.add_option('-e', '--detection', type='float', dest='det', default=10, help='detection weight [default: %default]')
    chaingraphopts.add_option('-m', '--misdetection', type='float', dest='mis', default=200, help='misdetection weight [default: %default]')

    
    consopts = optparse.OptionGroup(parser, "conservation tracking")
    consopts.add_option('--max-number-objects', dest='mno', type='float', default=2, help='Give maximum number of objects one connected component may consist of [default: %default]')
    consopts.add_option('--max-neighbor-distance', dest='mnd', type='float', default=30, help='[default: %default]')
    consopts.add_option('--division-threshold', dest='dt', type='float', default=0.5, help='[default: %default]')
    # detection_rf_filename in general parser options
    consopts.add_option('--size-dependent-detection-prob', dest='sddp', action='store_true')
    # forbidden_cost in general parser options
    # ep_gap in general parser options
    consopts.add_option('--average-obj-size', dest='aos', type='float', default=0, help='[default: %default]')
    consopts.add_option('--without-tracklets', dest='wot', action='store_true')
    consopts.add_option('--div', dest='dw', type='float', default=1.0, help='division weight [default: %default]')
    consopts.add_option('--tr', dest='tw', type='float', default=1.0, help='transition weight [default: %default]')
    consopts.add_option('--without-divisions', dest='wod', action='store_true')
    

    parser.add_option_group(chaingraphopts)
    parser.add_option_group(consopts)
    options, args = parser.parse_args()


    numArgs = len(args)
    if numArgs > 0:
        fns = []
        for arg in args:
            fns.extend(glob.glob(arg))
        fns.sort()
    else:
        parser.print_help()
        sys.exit(1)

    if not path.exists(options.out_dir):
        os.makedirs(options.out_dir)

    ### Copy input data
    """print "Copying input data..."
    fns = []
    for fn in fns:
        out_fn = path.join(options.out_dir, path.basename(fn))

        # test, if fn is a valid h5 file
        try:
            f_in = io.LineageH5(fn, 'r')
        except Exception as e:
            print e
            print "!! Not a valid H5 file: " + fn + " -> skipped"
            continue
        f_in.close()
        del f_in

        if options.full_copy:
            print "-- Copy: " + fn + " -> " + out_fn
            shutil.copy(fn, out_fn)
        else:
            print "-- Link/copy: " + fn + " -> " + out_fn
            with io.LineageH5(out_fn, 'w') as f_out:
                if options.with_rel_linking:
                    link_to = path.relpath(path.abspath(path.dirname(fn)), start=path.abspath(path.dirname(out_fn)))
                else:
                    link_to = path.abspath(path.dirname(fn))
                link_fn = path.join(link_to, path.basename(fn))
                f_out["features"] = h5py.ExternalLink(link_fn, "features")
                f_out["Input Segmentation"] = h5py.ExternalLink(link_fn, "Input Segmentation")
                f_out["Input Raw"] = h5py.ExternalLink(link_fn, "Input Raw")
                hdf
                with io.LineageH5(fn, 'r') as f_in:
                    f_in.copy("objects", f_out)
            del f_out
        
        #store out-filename for later use
        working_fns.append(out_fn)
    working_fns.sort()"""
    print

    ### Do the tracking
    start = time.time()
    
    feature_path='ObjectExtractionMultiClass'
    with_div = True
    if options.method=='chaingraph':
        feature_path='ObjectExtraction'
        with_div = False
    # read all traxels into TraxelStore
    print fns[0]
    time_range=[options.mints, options.maxts]
    if options.maxts == -1:
        time_range = None
    with h5py.File(fns[0], 'r') as h5file:
        ts = generate_traxelstore(h5file=h5file,
				  feature_path=feature_path,
				  time_range = time_range,
				  x_range = None,
				  y_range = None,
				  z_range = None,
				  size_range = [0, 10000],
				  x_scale=options.x_scale,
				  y_scale=options.y_scale,
				  z_scale=options.z_scale,
				  with_div=with_div,
				  with_local_centers=False,
				  median_object_size=None,
				  max_traxel_id_at=None)
	"""for i, fn in enumerate(working_fns):
        print "-- reading Traxels from " + fn
        f = io.LineageH5(fn, 'r', timestep=i)
        f.x_scale = options.x_scale
        f.y_scale = options.y_scale
        f.z_scale = options.z_scale
        traxels = f.cTraxels()
        ts.add_from_Traxels(traxels)
        f.close()
        del f
        print "-> %d traxels read" % len(traxels)"""

    info = [int(x) for x in ts.bounding_box()]
    t0, t1 = (info[0], info[4])
    print "-> Traxelstore bounding box: " + str(info)

    
    print "Start tracking..."
    if(options.method == "conservation"):
        rf_fn = 'none'
        if options.rf_fn:
            rf_fn = options.rf_fn
        tracker = track.ConsTracking(int(options.mno), options.mnd, options.dt, rf_fn, bool(options.sddp), options.forb, options.ep_gap, options.aos, not bool(options.wot), options.dw, options.tw, not bool(options.wod))
    elif(options.method == "chaingraph"):
        if(options.rf_fn):
            tracker = track.ChaingraphTracking(options.rf_fn, options.app, options.dis, options.det, options.mis, True, options.opp, options.forb, not(options.without_constraints), options.fixed_detections, options.mdd, options.ma, options.ep_gap)
        else:
            tracker = track.ChaingraphTracking("none", options.app, options.dis, options.det, options.mis, False, options.opp, options.forb, not(options.without_constraints), options.mdd, options.ma, options.ep_gap)
    else:
        raise Exception("unknown tracking method: " + options.method)

    events = tracker(ts)

    """print "Saving detections..."
    detections = tracker.detections()
    assert(len(detections) == len(working_fns))
    for i, detections_at in enumerate(detections):
        write_detections(detections_at, working_fns[i])"""

    print "Saving events..."
    print "Length of events " + str(len(events))
    working_fns = [options.out_dir.rstrip('/') + "/%04d.h5" % timestep for timestep in xrange(t0,t1+1)]
    assert(len(events) + 1 == len(working_fns))
    for i, events_at in enumerate(events):
        write_events(events_at, working_fns[i + 1])
        with h5py.File(fns[0], 'r') as src_file:
            with io.LineageH5(working_fns[i+1]) as dest_file:
                label_img = np.array(src_file[feature_path]['LabelImage'][t0+i+1,...,0])
                dg = dest_file.create_group('segmentation')
		ds = dg.create_dataset("labels", data=label_img, dtype=np.uint32)

		meta = dest_file.create_group('objects/meta')
		ids = np.unique(label_img)
		ids = ids[ids > 0]
		valid = np.ones(ids.shape)
		meta.create_dataset("id", data=ids[::-1], dtype=np.uint32)
		meta.create_dataset("valid", data=valid, dtype=np.uint32)
		
		


    stop = time.time()
    since = stop - start
    print "Elapsed time [s]: " + str(int(since))
    print "Elapsed time [min]: " + str(int(since) / 60)
    print "Elapsed time [h]: " + str(int(since) / 3600)
