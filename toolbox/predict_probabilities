#!/usr/bin/env python
import sys
sys.path.append('../.')
sys.path.append('.')
import numpy as np
import getpass
import glob
import socket
import shutil
import time
import os
import optparse
import h5py
import vigra

# load the feature "feature" of all objects from hdf5 file "f". Use new feature format.
def load_feature_new(f, feature):
    if "/objects/features/%s"%feature in f:
        return f["/objects/features/%s"%feature][:]
    else:
        print "Error: feature %s not found! Replaced by -1!"%feature
        return -1



# load the complete feature set in file "f"
def load_feature_set(f, feature_list = ['volume', 'bbox', 'position', 'com', 'pc', 'intensity', 'intminmax', 'pair', 'sgf', 'lcom', 'lpc', 'lintensity', 'lintminmax', 'lpair', 'lsgf']):
    
    feature_set = np.zeros((0,0),dtype=np.float32)
    if 'objects/features' in f:
        feature_set = np.zeros((load_feature_new(f,feature_list[0]).shape[0],0),dtype=np.float32)
        print "Using new feature format."
        for ft in feature_list:
            feature_set = np.append(feature_set, load_feature_new(f,ft), axis=1)
         
        return feature_set   
               
    elif 'features' in f:
        print "Warning: New feature format not found. Using old format."
        labelcount = f["features/labelcount"].value
        
        feature_set = np.zeros((0,198),dtype=np.float32)
        for i in range(1,labelcount+1):
            feature_vector = np.zeros((1,0),dtype=np.float32)
            for ft in feature_list:
                if "features/%i/%s"%(i,ft) in f:
                    feature_vector = np.append(feature_vector, np.reshape(f["features/%i/%s"%(i,ft)][:],(1,-1)), axis=1)
                else:
                    print "Error: feature %s not found for object %i!"%(ft,i)
                    f.close()
                    del f
                    sys.exit(1)  
            
            feature_set = np.append(feature_set,feature_vector, axis=0)
            
        return feature_set
    else:
        print "Error: No features found."
        f.close()
        del f
        sys.exit(1)



if __name__=="__main__":
    usage = """%prog [options] FILES
Predict probabilities or labels for all objects in HDF5 files FILES using a trained Random Forest classifier.
By default, only the prediction for class "1" is saved in dataset "prediction" in /objects/meta for every file. 

FILES: Files to analyze.
"""
    
    parser = optparse.OptionParser(usage=usage)

    parser.add_option('-f', '--rffile', type='str', dest='rf_file', default='./RandomForest.h5', help='Path to the vigra Random Forest [default: %default]')
    parser.add_option('-d', type='str', dest='out_dataset', default='prediction', help='Dataset to write the data to [default: %default]')    
    parser.add_option('-c', '--class', type='int', dest='write_class', default='1', help='Write result for this class [default: %default]')
    parser.add_option('-a', '--all-classes', type='str', dest='write_all', default='false', help='Write prediction for all classes. Predictions will be written in "[dataset]_class[x]". Overrides "-c" option. [default: %default]')
    parser.add_option('-l', '--predict-labels', type='str', dest='predict_labels', default='false', help='Predict labels instead of probabilities. "true" overrides options "-c" and "-a". [default: %default]')
    options, args = parser.parse_args()
    
    numArgs = len(args)
    if numArgs  > 0:
        filenames = []
        for arg in args:
            filenames.extend(glob.glob(arg))
    else:
        parser.print_help()
        sys.exit(1)
    filenames.sort()

    # Load the vigra Random forest
    RF = vigra.learning.RandomForest(options.rf_file)
    
    numclass = RF.labelCount()
    if options.write_class > numclass-1:
        print "Error: The desired class index for prediction (%i) exceeds the number of Random Forest classes (%i)."%(options.write_class,numclass)
        sys.exit(1)
        
    # Iterate over all files
    for fn in filenames:
        # Open hdf5 file and load features
        print 'Predicting file %s'%fn
        f = h5py.File(fn)
        features = load_feature_set(f)
        
        # Predict probabilities or labels
        if options.predict_labels == 'false':
            # predict probabilities
            probs = RF.predictProbabilities(features)
            
            # write to file
            if options.write_all == 'true':
                for i in range(numclass):
                    dname = "objects/meta/%s"%"%s_class%i"%(options.out_dataset,i)
                    
                    # delete old data if necessary
                    if dname in f:
                        del f[dname]
                        
                    # write to file
                    f.require_group("/objects")
                    f['objects'].require_group('meta')                    
                    ds = f.create_dataset(dname, data=probs[:,i])
                    ds.attrs["Date"] = time.ctime()
                    ds.attrs["User"] = getpass.getuser()
                    ds.attrs["Machine"] = socket.gethostname()
                    ds.attrs["RandomForest"] = options.rf_file
                    ds.attrs["Class"] = i
            else:
                dname = "objects/meta/%s"%options.out_dataset
                
                # delete old data if necessary
                if dname in f:
                    del f[dname]
                               
                # write to file
                f.require_group("/objects")
                f['objects'].require_group('meta')
                ds = f.create_dataset(dname, data=probs[:,options.write_class])
                ds.attrs["Date"] = time.ctime()
                ds.attrs["User"] = getpass.getuser()
                ds.attrs["Machine"] = socket.gethostname()
                ds.attrs["RandomForest"] = options.rf_file
                ds.attrs["Class"] = int(options.write_class)
                             
       
        else:
            # predict labels
            labels = RF.predictLabels(features)
            
            # delete old data if necessary
            if "/objects/meta/%s"%options.out_dataset in f:
                del f["/objects/meta/%s"%options.out_dataset]
            
            # write to file
            f.require_group("/objects")
            f['objects'].require_group('meta')
            ds = f.create_dataset("/objects/meta/%s"%options.out_dataset, data=labels)
            ds.attrs["Date"] = time.ctime()
            ds.attrs["User"] = getpass.getuser()
            ds.attrs["Machine"] = socket.gethostname()
            ds.attrs["RandomForest"] = options.rf_file
            ds.attrs["Class"] = "---labels---"        
        # close the file afterwards
        f.close()
        del f    
        
        

    print "-> Success!"

                    
                    
            
    
